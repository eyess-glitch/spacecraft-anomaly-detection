{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12067855,"sourceType":"datasetVersion","datasetId":7595946}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch_geometric","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T09:30:04.640000Z","iopub.execute_input":"2025-07-21T09:30:04.640250Z","iopub.status.idle":"2025-07-21T09:30:10.181664Z","shell.execute_reply.started":"2025-07-21T09:30:04.640226Z","shell.execute_reply":"2025-07-21T09:30:10.180743Z"}},"outputs":[{"name":"stdout","text":"Collecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.18)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (7.0.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.0.9)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch_geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\ntraining_df = pd.read_parquet(\"/kaggle/input/esa-telemetry-anomaly-detection/train.parquet\")\ntest_df = pd.read_parquet(\"/kaggle/input/esa-telemetry-anomaly-detection/test.parquet\")\n\ntarget_channels = pd.read_csv(\"/kaggle/input/esa-telemetry-anomaly-detection/target_channels.csv\")\ntarget_channels = target_channels.iloc[:,0].tolist()\nall_channels = training_df.columns.tolist()\nall_channels = [col for col in training_df.columns if col != 'id' and not col.startswith('telecommand') and col != 'is_anomaly']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T09:30:23.823030Z","iopub.execute_input":"2025-07-21T09:30:23.823749Z","iopub.status.idle":"2025-07-21T09:30:30.512258Z","shell.execute_reply.started":"2025-07-21T09:30:23.823723Z","shell.execute_reply":"2025-07-21T09:30:30.511723Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torch\nimport math\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import Sampler\n\nclass EsaDataset(Dataset):\n    def __init__(self, dataframe, target_channels, window_len, split_type):\n        self.df = dataframe\n        self.target_channels = target_channels\n        self.window_len = window_len\n        self.split_type = split_type\n\n    def __len__(self):\n        return len(self.df)\n        \n    def __getitem__(self, idx):\n        points = self.df.iloc[idx: idx + self.window_len]\n        x = torch.tensor(points[self.target_channels].values, dtype=torch.float32)\n        y = None\n        \n        if self.split_type == \"train\":\n            y = torch.tensor(points[\"is_anomaly\"].values, dtype=torch.float32)\n        \n        return x, y\n\nclass WindowedSampler(Sampler):\n    def __init__(self, data_source, window_size):\n        self.data_source = data_source\n        self.window_size = window_size\n\n    def __iter__(self):\n        return iter(range(0, len(self.data_source), self.window_size))\n\n    def __len__(self):\n        return math.ceil(len(self.data_source) / self.window_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T09:33:37.596320Z","iopub.execute_input":"2025-07-21T09:33:37.596982Z","iopub.status.idle":"2025-07-21T09:33:37.602975Z","shell.execute_reply.started":"2025-07-21T09:33:37.596956Z","shell.execute_reply":"2025-07-21T09:33:37.602334Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Can rewrite the lower methods with tensor operations and probably refactor them in a single one\n\ndef build_temporal_edges(batch_size, seq_len, device):\n    source, target = [], []\n    \n    for i in range(1, seq_len):\n        for j in range(max(0, i - seq_len), i):\n            source.append(j)\n            target.append(i)\n    \n    edge_index_single = torch.tensor([source, target], dtype=torch.long, device=device)\n    edges = []\n    offsets = torch.arange(batch_size, device=device) * seq_len  \n    edge_index_batch = edge_index_single.unsqueeze(2) + offsets.view(1, 1, -1)  # [2, num_edges_single, batch_size]\n    \n    return edge_index_batch.permute(2, 0, 1).reshape(2, -1)\n    \n\ndef build_variable_edges(num_channels, batch_size, device):\n    num_nodes = num_channels * batch_size\n    single_edge_index = torch.cartesian_prod(\n        torch.arange(num_channels, device=device), \n        torch.arange(num_channels, device=device)\n    ).t()\n\n    edge_indices = []\n    \n    for b in range(batch_size):\n        offset = b * num_channels\n        ei = single_edge_index + offset \n        edge_indices.append(ei)\n\n    edge_index = torch.cat(edge_indices, dim=1)\n    \n    return edge_index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T09:32:41.485870Z","iopub.execute_input":"2025-07-21T09:32:41.486654Z","iopub.status.idle":"2025-07-21T09:32:41.492989Z","shell.execute_reply.started":"2025-07-21T09:32:41.486628Z","shell.execute_reply":"2025-07-21T09:32:41.492265Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from torch_geometric.nn import MessagePassing\nfrom torch_geometric.utils import softmax\nimport torch.nn.functional as f\nimport torch\nimport torch.nn.utils.weight_norm as weight_norm\nimport torch.nn as nn\n\nclass GraphAttentionBlock(MessagePassing):\n    def __init__(self, in_channels):\n        super().__init__(aggr=\"sum\")\n        self.sigmoid = nn.Sigmoid() \n        self.leaky_relu = nn.LeakyReLU()\n        self.linear = nn.Linear(in_channels, in_channels)\n        self.a = nn.Parameter(torch.empty(in_channels*2,in_channels))       \n        nn.init.xavier_uniform_(self.a.data)                       \n       \n    def forward(self, X, edge_index):\n        X = self.linear(X)\n        return self.sigmoid(self.propagate(edge_index, x=X))\n\n    def message(self, x_j, x_i, index):\n        out = torch.cat([x_j, x_i], dim=1)\n        out = self.leaky_relu(out)\n        out = out @ self.a\n        alpha = softmax(out, index)\n        return x_j * alpha \n\nclass DGATnet(nn.Module):\n    def __init__(self, in_channels, num_layers):\n        super().__init__()\n        self.layers = nn.ModuleList()\n\n        for i in range(num_layers):\n            self.layers.append(GraphAttentionBlock(in_channels))        \n    \n    def forward(self, x, edge_index):\n        out = x\n        for layer in self.layers:\n            out = layer(out, edge_index)\n            \n        return out\n\nclass DilatedCausalConvBlock(nn.Module):\n    def __init__(self, in_channels, kernel_size):\n        super().__init__()\n        dilation_values = [1,2,4]\n        curr_channels = in_channels\n        self.blocks = nn.ModuleList()\n        self.relu = nn.ReLU()\n        \n        for d in dilation_values:\n            conv = weight_norm(nn.Conv1d(curr_channels, curr_channels, kernel_size, dilation=d))\n            # eventualmente aggiungere la batch norm\n            self.blocks.append(nn.Sequential(conv, self.relu))\n\n    def forward(self, X):\n        out = X\n        for i in range(len(self.blocks)):\n            padding = (self.blocks[i][0].kernel_size[0] - 1) * self.blocks[i][0].dilation[0]\n            out = f.pad(out, (padding, 0))\n            out = self.blocks[i](out)\n            \n        return out\n\nclass TCNblock(nn.Module):\n    def __init__(self, in_channels, kernel_size):\n        super().__init__()\n        self.dilated_causal_conv_block = DilatedCausalConvBlock(in_channels, kernel_size)\n        self.dropout = nn.Dropout(p=0.2)\n    \n    def forward(self, X):\n        out = self.dilated_causal_conv_block(X)\n        out = self.dropout(out)\n        return X + out\n\nclass TCNet(nn.Module):\n    def __init__(self, in_channels, num_layers, kernel_size):\n        super().__init__()\n        self.layers = nn.ModuleList()\n        for i in range (num_layers):\n            self.layers.append(TCNblock(in_channels, kernel_size))\n    \n    def forward(self, X):\n        out = X\n        for layer in self.layers:\n            out = layer(out)\n             \n        return out\n\nimport torch.nn.functional as F\n\n# Can probably rewrite DGATnet to have one network for temporal and variable attention\nclass ATCNet(nn.Module):\n    def __init__(self, seq_len, channels, kernel_size, num_layers_gat, num_layers_tcn, device):\n        super().__init__()\n        self.device = device\n        self.graph_temporal_att = DGATnet(channels, num_layers_gat)\n        self.graph_variable_att = DGATnet(seq_len, num_layers_gat)\n        self.conv1d = nn.Conv1d(in_channels=channels*2, out_channels=channels, kernel_size=1)\n        self.temp_conv_net = TCNet(channels, num_layers_tcn, kernel_size)\n    \n    # shape di X : batch_size,seq_len,channels\n    def forward(self, X):\n        batch_size, seq_len, channels = X.shape\n        \n        X_temporal = X.view(batch_size*seq_len, channels)\n        X_variable = X.permute(0,2,1)\n        X_variable = X_variable.reshape(channels*batch_size, seq_len)\n\n        temporal_edge_index = build_temporal_edges(batch_size, seq_len, self.device)\n        variable_edge_index = build_variable_edges(channels, batch_size, self.device)\n\n        temporal_att_embeddings = self.graph_temporal_att(X_temporal, temporal_edge_index)\n        variable_att_embeddings = self.graph_variable_att(X_variable, variable_edge_index)\n        \n        variable_att_embeddings = variable_att_embeddings.view(batch_size, channels, seq_len)\n        temporal_att_embeddings = temporal_att_embeddings.view(batch_size, seq_len, channels)\n        temporal_att_embeddings = temporal_att_embeddings.permute(0, 2, 1)\n    \n        features_matrix = torch.cat([temporal_att_embeddings, variable_att_embeddings], dim=1)\n        # dimensionality reduction\n        features_matrix = self.conv1d(features_matrix)\n        \n        predicted_sequence = self.temp_conv_net(features_matrix)\n        predicted_sequence = predicted_sequence.permute(0, 2, 1)\n    \n        return predicted_sequence\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T09:32:49.448568Z","iopub.execute_input":"2025-07-21T09:32:49.448853Z","iopub.status.idle":"2025-07-21T09:32:56.228470Z","shell.execute_reply.started":"2025-07-21T09:32:49.448832Z","shell.execute_reply":"2025-07-21T09:32:56.227944Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"batch_size, seq_len, channels = 64, 100, len(target_channels)\n    \nnum_of_training_samples_atcnet = int(len(training_df)*0.3)\nnum_of_training_samples_classifier = int(len(training_df) * 0.7)\n\ntraining_samples_df_atcnet = training_df[:num_of_training_samples_atcnet]\ntraining_samples_df_classifier = training_df[num_of_training_samples_atcnet: num_of_training_samples_atcnet + num_of_training_samples_classifier]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T09:33:54.993347Z","iopub.execute_input":"2025-07-21T09:33:54.993834Z","iopub.status.idle":"2025-07-21T09:33:54.997940Z","shell.execute_reply.started":"2025-07-21T09:33:54.993812Z","shell.execute_reply":"2025-07-21T09:33:54.997265Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\nimport itertools\nimport pandas as pd\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\n\ntrain_dataset_atcnet = EsaDataset(training_samples_df_atcnet, target_channels, seq_len, \"train\")\nsampler = WindowedSampler(train_dataset_atcnet, seq_len)\ntrain_loader_atcnet = DataLoader(\n    train_dataset_atcnet,\n    batch_size=batch_size,       \n    shuffle=False,        \n    num_workers=0, \n    sampler=sampler,\n    drop_last=True\n)\n    \ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\natcnet = ATCNet(seq_len=seq_len, channels=channels, kernel_size=4, num_layers_gat=3, num_layers_tcn=3, device=device)              \natcnet = atcnet.to(device)            \n         \noptimizer = optim.Adam(atcnet.parameters(), lr=1e-3)\nnum_epochs = 1\niteration_counter = 0\n    \nbatch_losses = []\n\nfor epoch in range(num_epochs):\n    atcnet.train()  \n    train_loss = 0.\n    last_predicted_window = torch.zeros(1, seq_len, channels).to(device)\n\n    for batch in tqdm(train_loader_atcnet): \n        inputs, _ = batch\n        inputs = inputs.to(device)\n        predicted_sequences = atcnet(inputs).to(device)\n\n        current_batch_size = inputs.shape[0]\n        predicted_sequences = torch.cat([last_predicted_window, predicted_sequences[:current_batch_size-1]], dim=0)\n        last_predicted_window = predicted_sequences[current_batch_size-1].unsqueeze(0).detach()\n\n        error_abs = torch.abs(inputs - predicted_sequences)\n        mse_loss = ((inputs - predicted_sequences)**2).mean()\n        mae_loss = error_abs.mean()\n\n        train_loss += mse_loss.item()\n        batch_losses.append(mse_loss.item())\n\n        if iteration_counter % 50 == 0:\n            print(f\"\\n[Iteration {iteration_counter}] Batch Loss: {mae_loss.item():.6f}\")\n\n        optimizer.zero_grad()\n        mse_loss.backward()\n        optimizer.step()\n        \n        iteration_counter += 1\n","metadata":{"execution":{"iopub.status.busy":"2025-07-21T09:33:57.084605Z","iopub.execute_input":"2025-07-21T09:33:57.085138Z","iopub.status.idle":"2025-07-21T09:35:53.119282Z","shell.execute_reply.started":"2025-07-21T09:33:57.085112Z","shell.execute_reply":"2025-07-21T09:35:53.118648Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n  WeightNorm.apply(module, name, dim)\n  0%|          | 0/690 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"\n[Iteration 0] Batch Loss: 0.572052\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 52/690 [00:09<01:46,  6.02it/s]","output_type":"stream"},{"name":"stdout","text":"\n[Iteration 50] Batch Loss: 0.030643\n","output_type":"stream"},{"name":"stderr","text":" 15%|█▍        | 102/690 [00:18<01:37,  6.01it/s]","output_type":"stream"},{"name":"stdout","text":"\n[Iteration 100] Batch Loss: 0.014587\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 152/690 [00:26<01:29,  6.02it/s]","output_type":"stream"},{"name":"stdout","text":"\n[Iteration 150] Batch Loss: 0.008916\n","output_type":"stream"},{"name":"stderr","text":" 29%|██▉       | 202/690 [00:34<01:21,  6.01it/s]","output_type":"stream"},{"name":"stdout","text":"\n[Iteration 200] Batch Loss: 0.007060\n","output_type":"stream"},{"name":"stderr","text":" 37%|███▋      | 252/690 [00:43<01:12,  6.01it/s]","output_type":"stream"},{"name":"stdout","text":"\n[Iteration 250] Batch Loss: 0.005181\n","output_type":"stream"},{"name":"stderr","text":" 44%|████▍     | 302/690 [00:51<01:04,  5.99it/s]","output_type":"stream"},{"name":"stdout","text":"\n[Iteration 300] Batch Loss: 0.004545\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 352/690 [00:59<00:56,  6.02it/s]","output_type":"stream"},{"name":"stdout","text":"\n[Iteration 350] Batch Loss: 0.006408\n","output_type":"stream"},{"name":"stderr","text":" 58%|█████▊    | 402/690 [01:07<00:47,  6.02it/s]","output_type":"stream"},{"name":"stdout","text":"\n[Iteration 400] Batch Loss: 0.005056\n","output_type":"stream"},{"name":"stderr","text":" 66%|██████▌   | 452/690 [01:16<00:39,  6.01it/s]","output_type":"stream"},{"name":"stdout","text":"\n[Iteration 450] Batch Loss: 0.005418\n","output_type":"stream"},{"name":"stderr","text":" 73%|███████▎  | 502/690 [01:24<00:31,  6.02it/s]","output_type":"stream"},{"name":"stdout","text":"\n[Iteration 500] Batch Loss: 0.005792\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 552/690 [01:32<00:22,  6.02it/s]","output_type":"stream"},{"name":"stdout","text":"\n[Iteration 550] Batch Loss: 0.003944\n","output_type":"stream"},{"name":"stderr","text":" 87%|████████▋ | 602/690 [01:41<00:14,  6.01it/s]","output_type":"stream"},{"name":"stdout","text":"\n[Iteration 600] Batch Loss: 0.003245\n","output_type":"stream"},{"name":"stderr","text":" 94%|█████████▍| 652/690 [01:49<00:06,  6.01it/s]","output_type":"stream"},{"name":"stdout","text":"\n[Iteration 650] Batch Loss: 0.003896\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 690/690 [01:55<00:00,  5.96it/s]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import torch\nimport numpy as np \nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nfrom tqdm import tqdm\n\nfrom torch.nn.utils.rnn import pad_sequence\nimport torch\n\ntraining_dataset_cls = EsaDataset(training_samples_df_classifier, target_channels, seq_len, \"train\")\ncls_sampler = WindowedSampler(training_dataset_cls, seq_len)\n\ntrain_loader_cls = DataLoader(\n    training_dataset_cls,\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=0,\n    sampler=cls_sampler,\n    drop_last=True)\n\nfeature_matrix_train_cls = []\ntrain_labels = []\n\natcnet.eval()\n\nlast_predicted_window = torch.zeros(1, seq_len, channels).to(device)\nlast_window_input = torch.zeros(channels, seq_len).to(device)\n\nfor inputs, targets in tqdm(train_loader_cls):\n    inputs = inputs.to(device)  # (batch_size, seq_len, channels)\n    targets = targets.to(device)\n    actual_batch_size = inputs.shape[0]\n\n    with torch.no_grad():\n        predicted_sequences = atcnet(inputs)  # (batch_size, seq_len, channels)\n\n        predicted_sequences = torch.cat(\n            [last_predicted_window, predicted_sequences[:actual_batch_size - 1]],\n            dim=0\n        )\n        \n        last_predicted_window = predicted_sequences[actual_batch_size - 1].unsqueeze(0).detach()\n\n        model_errors = torch.abs(inputs - predicted_sequences)  \n        model_errors = model_errors.view(actual_batch_size * seq_len, channels).cpu().numpy()\n        \n        feature_matrix_train_cls.append(model_errors)\n        train_labels.append(targets.view(batch_size*seq_len).cpu().numpy())\n\nfeature_matrix_train_cls = np.concatenate(feature_matrix_train_cls, axis=0)\ntrain_labels = np.concatenate(train_labels, axis=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T09:35:56.943286Z","iopub.execute_input":"2025-07-21T09:35:56.943576Z","iopub.status.idle":"2025-07-21T09:38:43.842940Z","shell.execute_reply.started":"2025-07-21T09:35:56.943553Z","shell.execute_reply":"2025-07-21T09:38:43.842321Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1610/1610 [02:46<00:00,  9.69it/s]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import numpy as np\n\nnp.random.seed(42)\n\nidx_1_full = np.where(train_labels == 1)[0]\nidx_0_full = np.where(train_labels == 0)[0]\n\nnp.random.shuffle(idx_1_full)\nnp.random.shuffle(idx_0_full)\n\nn_samples   = min(len(idx_1_full), len(idx_0_full))\nidx_1_train = idx_1_full[:n_samples]\nidx_0_train = idx_0_full[:n_samples]\n\nselected_indices   = np.concatenate([idx_1_train, idx_0_train])\nnp.random.shuffle(selected_indices)\n\nbalanced_features  = feature_matrix_train_cls[selected_indices]\nbalanced_labels    = train_labels[selected_indices]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T09:43:09.863954Z","iopub.execute_input":"2025-07-21T09:43:09.864258Z","iopub.status.idle":"2025-07-21T09:43:10.755010Z","shell.execute_reply.started":"2025-07-21T09:43:09.864237Z","shell.execute_reply":"2025-07-21T09:43:10.754420Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(random_state=42, n_estimators=200, max_depth=10)\nmodel.fit(balanced_features, balanced_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T10:12:35.959874Z","iopub.execute_input":"2025-07-20T10:12:35.960135Z","iopub.status.idle":"2025-07-20T11:04:28.191256Z","shell.execute_reply.started":"2025-07-20T10:12:35.960117Z","shell.execute_reply":"2025-07-20T11:04:28.190573Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, n_estimators=200, random_state=42)</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"def collate_fn_test(batch):\n    if isinstance(batch[0], tuple):\n        inputs = [item[0] for item in batch]\n    else:\n        inputs = batch\n\n    padded_inputs = pad_sequence(inputs, batch_first=True, padding_value=0.0)  # shape (batch_size, max_seq_len, channels)\n    return padded_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T09:45:09.004211Z","iopub.execute_input":"2025-07-21T09:45:09.004904Z","iopub.status.idle":"2025-07-21T09:45:09.008807Z","shell.execute_reply.started":"2025-07-21T09:45:09.004879Z","shell.execute_reply":"2025-07-21T09:45:09.008040Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import torch\nimport numpy as np \nfrom torch.utils.data import DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nfrom tqdm import tqdm\n\ntest_dataset = EsaDataset(test_df, target_channels, seq_len, \"test\")\ntest_sampler = WindowedSampler(test_dataset, seq_len)\n\ntest_loader_real = DataLoader(\n    test_dataset,\n    batch_size=batch_size,\n    shuffle=False,\n    num_workers=0,\n    sampler=test_sampler,\n    drop_last=False,\n    collate_fn=collate_fn_test\n)\n\nfeature_matrix_test = []\natcnet.eval()\n\nlast_predicted_window = torch.zeros(1, seq_len, channels).to(device)\nlast_window_input = torch.zeros(channels, seq_len).to(device)\n\nfor inputs in tqdm(test_loader_real, desc=\"Test Evaluation\"):\n    inputs = inputs.to(device)  # inputs shape: (batch_size, seq_len, channels)\n    actual_batch_size = inputs.shape[0]\n\n    with torch.no_grad():\n        predicted_sequences = atcnet(inputs)  # output shape (batch_size, seq_len, channels)\n        predicted_sequences = torch.cat(\n            [last_predicted_window, predicted_sequences[:actual_batch_size - 1]],\n            dim=0\n        )\n        last_predicted_window = predicted_sequences[actual_batch_size - 1].unsqueeze(0).detach()\n\n        model_errors = torch.abs(inputs - predicted_sequences)  # shape (batch_size, seq_len, channels)\n        \n        # Flatten e salva\n        model_errors = model_errors.view(actual_batch_size * seq_len, channels).cpu().numpy()\n        feature_matrix_test.append(model_errors)\n\nfeature_matrix_test = np.concatenate(feature_matrix_test, axis=0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-21T09:45:39.632179Z","iopub.execute_input":"2025-07-21T09:45:39.632471Z","iopub.status.idle":"2025-07-21T09:45:47.664214Z","shell.execute_reply.started":"2025-07-21T09:45:39.632450Z","shell.execute_reply":"2025-07-21T09:45:47.663445Z"}},"outputs":[{"name":"stderr","text":"Test Evaluation: 100%|██████████| 82/82 [00:07<00:00, 10.26it/s]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import pandas as pd\n\ny_pred = model.predict(feature_matrix_test_real)\nstart_id = 14728321\nids = range(start_id, start_id + len(y_pred))\n\n# Crea DataFrame\ndf_out = pd.DataFrame({\n    \"id\": ids,\n    \"is_anomaly\": y_pred\n})\n\ndf_out = df_out.iloc[:521280]\n# Salva in file parquet\ndf_out.to_parquet(\"predictions.parquet\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T11:34:18.735837Z","iopub.execute_input":"2025-07-20T11:34:18.736114Z","iopub.status.idle":"2025-07-20T11:34:24.591150Z","shell.execute_reply.started":"2025-07-20T11:34:18.736096Z","shell.execute_reply":"2025-07-20T11:34:24.590305Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"model = RandomForestClassifier(random_state=42, n_estimators=200, max_depth=10)\natcnet = ATCNet(seq_len=seq_len, channels=channels, kernel_size=4, num_layers_gat=6, num_layers_tcn=6, device=device)              \n","metadata":{}},{"cell_type":"code","source":"df_out['is_anomaly'].sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T11:34:27.556284Z","iopub.execute_input":"2025-07-20T11:34:27.557000Z","iopub.status.idle":"2025-07-20T11:34:27.562491Z","shell.execute_reply.started":"2025-07-20T11:34:27.556976Z","shell.execute_reply":"2025-07-20T11:34:27.561770Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"5.0"},"metadata":{}}],"execution_count":30}]}